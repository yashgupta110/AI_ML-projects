{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f18465ad-044e-47b2-9849-8056a6cbe497",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.18.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b2de66b-0c0d-4c30-ac66-435a9520f41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5eb4c3be-852d-45e9-a79a-673478e4de74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8005 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1/255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n",
    "training_set = train_datagen.flow_from_directory(\"Cats & Dogs/training_set/training_set\",target_size=(64,64),batch_size=32,class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "509acb7d-0e5c-4264-b0cd-e337521b25f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2023 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1/255)\n",
    "test_set = train_datagen.flow_from_directory(\"Cats & Dogs/test_set/test_set\",target_size=(64,64),batch_size=32,class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f126b1ec-2948-4dff-acbd-8ce1c2ecf3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2387e809-2109-458b-ac66-03e9fb243070",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ysgup\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32,activation='relu',kernel_size=3,input_shape= [64,64,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42099327-f751-405b-878d-bd6b7fc2cd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cd5bc76-2ab1-4c39-a126-8b8a9b6cb7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32,activation='relu',kernel_size=3))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf4e5964-93db-468f-9212-9cc6823241ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff6223cf-db84-49d1-8db1-0fccbe114268",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(activation='relu',units=128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39baa759-3b6a-4aa6-8223-039d2caedb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(activation='sigmoid',units=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66d283f2-3abd-4ba6-b0a7-0fffc63fc608",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b46a09a7-02d8-48b0-b5b9-0d2aceff18c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ysgup\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.5382 - loss: 0.6890"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ysgup\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 97ms/step - accuracy: 0.5383 - loss: 0.6890 - val_accuracy: 0.6258 - val_loss: 0.6394\n",
      "Epoch 2/25\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 97ms/step - accuracy: 0.6469 - loss: 0.6281 - val_accuracy: 0.6718 - val_loss: 0.5944\n",
      "Epoch 3/25\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 96ms/step - accuracy: 0.6999 - loss: 0.5799 - val_accuracy: 0.7004 - val_loss: 0.5878\n",
      "Epoch 4/25\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 96ms/step - accuracy: 0.7191 - loss: 0.5452 - val_accuracy: 0.7158 - val_loss: 0.5787\n",
      "Epoch 5/25\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 98ms/step - accuracy: 0.7449 - loss: 0.5109 - val_accuracy: 0.7637 - val_loss: 0.5125\n",
      "Epoch 6/25\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 106ms/step - accuracy: 0.7532 - loss: 0.4963 - val_accuracy: 0.7435 - val_loss: 0.5177\n",
      "Epoch 7/25\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 114ms/step - accuracy: 0.7719 - loss: 0.4789 - val_accuracy: 0.7494 - val_loss: 0.5131\n",
      "Epoch 8/25\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 110ms/step - accuracy: 0.7845 - loss: 0.4545 - val_accuracy: 0.7776 - val_loss: 0.4920\n",
      "Epoch 9/25\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 128ms/step - accuracy: 0.7898 - loss: 0.4475 - val_accuracy: 0.7207 - val_loss: 0.5579\n",
      "Epoch 10/25\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 115ms/step - accuracy: 0.7836 - loss: 0.4615 - val_accuracy: 0.7726 - val_loss: 0.4867\n",
      "Epoch 11/25\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 93ms/step - accuracy: 0.7979 - loss: 0.4339 - val_accuracy: 0.7825 - val_loss: 0.4823\n",
      "Epoch 12/25\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 93ms/step - accuracy: 0.8154 - loss: 0.4108 - val_accuracy: 0.7751 - val_loss: 0.4627\n",
      "Epoch 13/25\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 93ms/step - accuracy: 0.8129 - loss: 0.4084 - val_accuracy: 0.7642 - val_loss: 0.4910\n",
      "Epoch 14/25\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 93ms/step - accuracy: 0.8228 - loss: 0.3913 - val_accuracy: 0.7924 - val_loss: 0.4531\n",
      "Epoch 15/25\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 93ms/step - accuracy: 0.8290 - loss: 0.3881 - val_accuracy: 0.7958 - val_loss: 0.4784\n",
      "Epoch 16/25\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 94ms/step - accuracy: 0.8255 - loss: 0.3782 - val_accuracy: 0.7860 - val_loss: 0.4672\n",
      "Epoch 17/25\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 96ms/step - accuracy: 0.8311 - loss: 0.3678 - val_accuracy: 0.7845 - val_loss: 0.4784\n",
      "Epoch 18/25\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 94ms/step - accuracy: 0.8435 - loss: 0.3505 - val_accuracy: 0.7904 - val_loss: 0.4701\n",
      "Epoch 19/25\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 92ms/step - accuracy: 0.8439 - loss: 0.3484 - val_accuracy: 0.8033 - val_loss: 0.4493\n",
      "Epoch 20/25\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 93ms/step - accuracy: 0.8550 - loss: 0.3360 - val_accuracy: 0.7958 - val_loss: 0.4903\n",
      "Epoch 21/25\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 95ms/step - accuracy: 0.8448 - loss: 0.3379 - val_accuracy: 0.7924 - val_loss: 0.4748\n",
      "Epoch 22/25\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 93ms/step - accuracy: 0.8580 - loss: 0.3238 - val_accuracy: 0.7919 - val_loss: 0.4844\n",
      "Epoch 23/25\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 175ms/step - accuracy: 0.8633 - loss: 0.3141 - val_accuracy: 0.7963 - val_loss: 0.4707\n",
      "Epoch 24/25\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 228ms/step - accuracy: 0.8703 - loss: 0.3023 - val_accuracy: 0.7874 - val_loss: 0.5058\n",
      "Epoch 25/25\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 100ms/step - accuracy: 0.8802 - loss: 0.2845 - val_accuracy: 0.8033 - val_loss: 0.4693\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1f9ac1c9130>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(x = training_set,validation_data=test_set, epochs=25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
